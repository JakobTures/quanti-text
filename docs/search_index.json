[["index.html", "Quantitative Textanalyse mit R Einleitung Quantitative Textanalyse Kursinhalte Konventionen Danksagung Colophon", " Quantitative Textanalyse mit R Jakob Tures 2021-08-31 Einleitung Quantitative Textanalyse Quantitative Textanalyse umfasst die Anwendung statistischer Methoden auf – in erster Linie – geschriebene Sprache. Darunter fallen unter anderem das einfache Zählen von Worthäufigkeiten, die Analyse von Korrelationen und Netzwerken zwischen Wörtern, das Erkennen der emotionalen Haltung in geschriebener Sprache und die automatisierte Einordnung von Texten in latente oder explizite Kategorien. Diese und andere Techniken der quantiativen Textanalyse werden wir in diesem Kurs behandeln. Texte als Datenbasis empirischer Wissenschaft kommen vor allem in der qualitativen Forschung zum Einsatz. Hier werden Texte “per Hand” nach Ihren Bedutungsinhalten kodiert oder kategorisiert. Dies hat den Vorteil, dass Sprache in ihrem Kontext und ihrer enormen Komplexität von Menschen verstanden wird und Ebenen analysiert werden können die tiefer liegen als das reine geschriebene Wort es ausdrücken könnte. In der quantitativen Textanalyse nutzen wir hingegen vor allem computergestützte Methoden. Computer können menschliche Sprache jedoch nicht in dem Sinne verstehen, wie eine menschliche Kodiererin dies kann. Möchten wir beispielsweise den emotionalen Gehalt eines Textes – das sentiment – analysieren, können wir ein dictionary mit nach Emotionen kodierten Wörtern an unsere Textdaten anlegen, die Relation von “positiven” und “negativen” Wörtern berechnen und Aussagen zu dem durchschnittlichen sentiment eines Textes treffen. Da bei diesen relativ einfachen Techniken in der Regel nur einzelne Wörter für sich betrachtet werden, kann der Computer bereits Probleme mit der Verneinung von Begriffen haben. “Nicht gut” können wir als Menschen sofort als negativ verstehen während unsere Software “nicht” und “gut” getrennt betrachtet und so im besten Fall ein neutrales, im schlimmsten Fall ein positives sentiment erkennt. Noch schwieriger wird es Ironie, Humor, Anspielungen usw. adäquat mit den Mitteln der quantitiven Analyse zu erfassen, eine Aufgabe die vor allem in der geschriebenen Sprache bereits für Menschen schwierig sein kann – vermutlich kennt jeder von uns die Situation, das sentiment von Textnachrichten falsch ausgelegt zu haben. Auch bei der Anwendung der ausgfeilteren Methoden quantitativer Textanalyse müssen wir uns dieser Beschränkungen stets bewusst sein. Unsere Techniken und Algorithmen werden die Fähigkeit menschlicher Kodiererinnen Sprache in ihrem Kontext zu verstehen nicht erreichen. Somit drängt sich natürlich die Frage zwingend auf, warum sollten wir überhaupt Sprache computergestützt analysieren? Auch wenn wir die beschriebenen Einschränkungen nicht “wegrationalisieren” können, bringt die quantiative Textanalyse auch enorme Vorteile mit sich. Zunächst steht uns ein umfangreicher Werkzeugkoffer voller hochentwickelter Methoden zur Verfügung um zum Einen den Fehler gering zu halten und diesen zum Anderen quantifizierbar zu machen. Auch überlassen wir den Computer in der Textanalyse nicht sich selbst, sondern treffen bewusste Entscheidungen in der Gestaltung der Analyse und interpretieren die Ergebnisse im Bewusstsein der Komplexität von Sprache und der Grenzen unserer Methoden mit kritischem Blick. Wir können also mit den Einschränkungen der Methode bewusst und möglichst objektiv umgehen, dies ist aber weiterhin noch kein Argument für die quantitative Textanalyse. Was diese aber im Gegensatz zu qualitativer Textanalyse möglich macht, ist die Analyse großer Datenmengen in kurzer Zeit. Menschliches Kodieren von Texten ist sehr zeitaufwendig und beschränkt sich in der Regel auf eine geringe Anzahl von Dokumenten. In der computergestützten Textanalyse können wir hingegen enorm große Textmengen in relativ wenig Zeit analysieren. Wenn ein sehr großes Analyseprojekt mit aufwendigen Algorithmen mehrere Stunden Rechenzeit in Anspruch nimmt – diese Größenordnung werden wir in disem Kurs nicht erreichen – steht dies im Verhältnis zu mehreren Jahren Arbeitszeit menschlicher Kodierer*innen. Im Rahmen dieses Kurses werden wir die Plenarprotokolle des 19. Deutschen Bundestags analysieren. Dies sind mehr als 200 Protokolle mit jeweils bis zu mehreren hundert Seiten Text. Diese per Hand zu analysieren ist mehr oder weniger unmöglich. Computergestützt wird aus “unmöglich” jedoch nicht nur “machbar”, sondern wir können uns während der Rechenzeit sogar noch einen Kaffee holen. Ein weiteres starkes Argument für quantitative Textanalyse ist aus meiner Sicht die Nachvollziehbarkeit und Transparenz der Analyse. Jede Nutzerin mit Zugang zu den Daten und unserem R-scripts kann die Analyse replizieren oder auch modifizieren. Diese Replizierbarkeit ist eine fundamentale Säule empirischer Wissenschaft und unabhängig von der nicht in Frage gestellten Fähigkeit und Gründlichkeit qualitativer Forscherinnen dort in dieser Form nicht möglich. Eine letzte einleitende Bemerkung: Auch wenn ich in den obrigen zeilen viele Vergleiche zur qualitativen Textanalyse – der klassischen “Heimat” von Textanalysen – gezogen habe, möchte ich klar betonen, dass es mir weder um eine Aufwertung des einen noch um eine Abwertung des anderen Ansatzes geht. Qualitative Methoden eröffnen Fragestellungen die den quantitativen verschlossen bleiben und andersherum. Die relevante Frage ist also nicht, welcher Ansatz ist “besser”, sondern welcher ist adäquat für mein Forschungsinteresse? Beispiele Kursinhalte Der erste Block des Kurses (Kapitel 1, 2 &amp; 3) umfasst eine Einführung in R und RStudio. R ist eine Programmiersprache die vor allem für statistische Analysen Anwendung findet. Die Grundfunktionen von R können durch das Einbinden von professionellen und nutzergeschriebenen packages erweitert werden. Diese Erweiterungen sind es, die R so flexibel machen und neben statistischen Analysen unter anderem auch das Schreiben von Websiten direkt in R – so wie diese Website – und die Aufbereitung und Analyse von Textdaten ermöglichen. RStudio ist ein IDE – integrated development environment – für R und vereinfacht das Arbeiten mit der Sprache. Der erste Block umfasst Informationen zur Installation beider Softwares, der Bedienung von RStudio sowie grundlegenden R Befehlen. Abgeschlossen wird er mit einem Überblick zur Transformation von Daten und deren graphischer Analyse mit dem verbreiteten R package tidyverse. Kapitel 4 befasst sich mit dem Datensatz der im Kurs zur Textanalyse verwendet wird, den Plenarprotokollen des 19. Deutschen Bundestags. Wir betrachten den Inhalt des Datensatzes sowie dessen Struktur. Im dritten Block (Kapitel 5, 6, 7 &amp; 8) beginnt die eigentliche Textanalyse. Wir nutzen dazu das tidytext package, welches nach der Logik des tidyverse funktioniert und sich somit sehr gut in dessen datenanalytischen workflow integriert. Wir beginnen mit dem Umgang mit Textdaten und der statistischen Analyse einzelner Wörter bevor wir uns der Arbeit mit Wortkombinationen widmen. Abgeschlossen wird der Block mit Techniken zur sentiment Analyse anhand eines dictionaries. Block Vier (Kapitel 9, 10 &amp; ??) führt ein weiteres package zur quantitativen Textanalyse ein, quanteda. Dieses nutzt eine alternative Struktur für Textdaten, deren Prinzipien wir beleuchten und uns damit auseinandersetzen, wie wir sie mit dme tidyverse integrieren können. Im Weiteren befassen wir uns mit grundlegenden Textanalyse Techniken in quanteda und vor allem mit Methoden die über die Möglichkeiten von tidytext hinausgehen. Der abschließenden fünften Block (Kapitel 12 &amp; 13) führt in die Techniken des machine learnings ein. Wir betrachten wie wir unsupervised machine learning nutzen können um latente Dimensionen in unkategorisierten Textdaten zu erkennen und diese automatisch nach Gemeinsamkeiten und Unterschiedenen zu gruppieren. Im supervised machine learning geben wir für einen Teil der Daten Kategorien vor um mit dem so trainierten Modell neue ungesehene Daten zu kategorieseren. Dabei gehen wir auch auf die Unterschiede und potentiellen anwendungsfälle beider Ansätze ein. Konventionen Die R Welt ist eine englischssprachige Welt. Die Namen von packages und Funktionen sind meist mehr oder weniger sprechend und stets Englisch. Auch sind die meisten Begriffe die sich auf R und RStudio beziehen englischsprachig. Sinnvolle Übersetzungen existieren meist nicht. Auch wäre es nicht zielführend diese Begriffe selbst zu übersetzen da dies nur unnötig verwirren würde. Einer der wichtigsten Skills die Sie im Umgang mit einer Sprache wie R entwickeln müssen, ist das gezielte googlen nach Problemen bzw. Lösungen. Dazu benötigen Sie das englischsprachige Fachvokabular. Dies alles spräche dafür diese Einführung in Englisch zu verfassen. Da aber das Datennmaterial, die Plenarprotokolle, Deutsche Texte sind, blieb als Option nur der Kompromiss die Seite auf Deutsch zu schreiben und die englischsprachigen Fachbegriffe einzubinden ohne sie zu übersetzen. Die Namen von R packages werden fett geschrieben. Da R case sensitive, also Groß- und Kleinschreibung nicht beliebig austauschbar ist, werden die Namen der packages exakt so geschrieben, wie sie benannt sind. Ein Beispiel ist: tidytext Alle Codebeispiele sind in code font gesetzt. Teilweise im Text: print(\"Hello World\"), teilweise als code block: print(&quot;Hello World!&quot;) ## [1] &quot;Hello World!&quot; Der output des R codes wird direkt innerhalb des code blocks hinter ## gedruckt. Ich empfehle dringend den Inhalt der code blocks selbst in RStudio laufen zu lassen und den code dabei auch selbst zu tippen statt ihn zu kopieren. Um eine Sprache wir R zu erlernen, muss man sie regelmäßig selbst tippen. Nur so können die Namen häufig genutzter Funktionen sowie die R syntax in Ihr “muscle memory” übergehen. Danksagung Besonderer Dank gilt Lukas Höttges für die Unterstützung bei der Erstellung dieser Website und der Durchführung des korrespondierenden Seminars an der Universität Potsdam im Wintersemester 2021/22. Gleichermaßen danke ich den aktuellen und ehemaligen Teammitgliedern des Lehrstuhls für Methoden der empirischen Sozialforschung an der Universität Potsdam für ihr wertvolles Feedback zu technischen und inhaltlichen Fragen in diversen Kaffeepausen und Zoom-Gesprächen. Dank gilt auch den Erstellern der diversen genutzten R packages, insbesondere bookdown, tidyverse, tidytext und quanteda sowie der gesamten R community. Colophon Bei der Gestaltung dieser website sowie der vorgestellten code Beispiele kam Folgendes zum Einsatz: sessioninfo::session_info() ## ─ Session info ─────────────────────────────────────────────────────────────── ## setting value ## version R version 4.1.1 (2021-08-10) ## os Ubuntu 20.04.3 LTS ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Europe/Berlin ## date 2021-08-31 ## ## ─ Packages ─────────────────────────────────────────────────────────────────── ## package * version date lib source ## assertthat 0.2.1 2019-03-21 [1] CRAN (R 4.1.1) ## backports 1.2.1 2020-12-09 [1] CRAN (R 4.1.1) ## bookdown * 0.23 2021-08-13 [1] CRAN (R 4.1.1) ## broom 0.7.9 2021-07-27 [1] CRAN (R 4.1.1) ## bslib 0.2.5.1 2021-05-18 [1] CRAN (R 4.1.1) ## cellranger 1.1.0 2016-07-27 [1] CRAN (R 4.1.1) ## cli 3.0.1 2021-07-17 [1] CRAN (R 4.1.1) ## codetools 0.2-18 2020-11-04 [4] CRAN (R 4.0.3) ## colorspace 2.0-2 2021-06-24 [1] CRAN (R 4.1.1) ## crayon 1.4.1 2021-02-08 [1] CRAN (R 4.1.1) ## DBI 1.1.1 2021-01-15 [1] CRAN (R 4.1.1) ## dbplyr 2.1.1 2021-04-06 [1] CRAN (R 4.1.1) ## digest 0.6.27 2020-10-24 [1] CRAN (R 4.1.1) ## dplyr * 1.0.7 2021-06-18 [1] CRAN (R 4.1.1) ## ellipsis 0.3.2 2021-04-29 [1] CRAN (R 4.1.1) ## evaluate 0.14 2019-05-28 [1] CRAN (R 4.1.1) ## fansi 0.5.0 2021-05-25 [1] CRAN (R 4.1.1) ## fastmap 1.1.0 2021-01-25 [1] CRAN (R 4.1.1) ## fastmatch 1.1-3 2021-07-23 [1] CRAN (R 4.1.1) ## forcats * 0.5.1 2021-01-27 [1] CRAN (R 4.1.1) ## fs 1.5.0 2020-07-31 [1] CRAN (R 4.1.1) ## generics 0.1.0 2020-10-31 [1] CRAN (R 4.1.1) ## ggplot2 * 3.3.5 2021-06-25 [1] CRAN (R 4.1.1) ## glue 1.4.2 2020-08-27 [1] CRAN (R 4.1.1) ## gtable 0.3.0 2019-03-25 [1] CRAN (R 4.1.1) ## haven 2.4.3 2021-08-04 [1] CRAN (R 4.1.1) ## hms 1.1.0 2021-05-17 [1] CRAN (R 4.1.1) ## htmltools 0.5.2 2021-08-25 [1] CRAN (R 4.1.1) ## httr 1.4.2 2020-07-20 [1] CRAN (R 4.1.1) ## janeaustenr 0.1.5 2017-06-10 [1] CRAN (R 4.1.1) ## jquerylib 0.1.4 2021-04-26 [1] CRAN (R 4.1.1) ## jsonlite 1.7.2 2020-12-09 [1] CRAN (R 4.1.1) ## knitr * 1.33 2021-04-24 [1] CRAN (R 4.1.1) ## lattice 0.20-44 2021-05-02 [4] CRAN (R 4.1.0) ## lifecycle 1.0.0 2021-02-15 [1] CRAN (R 4.1.1) ## lubridate 1.7.10 2021-02-26 [1] CRAN (R 4.1.1) ## magrittr 2.0.1 2020-11-17 [1] CRAN (R 4.1.1) ## Matrix 1.3-4 2021-06-01 [4] CRAN (R 4.1.0) ## modelr 0.1.8 2020-05-19 [1] CRAN (R 4.1.1) ## munsell 0.5.0 2018-06-12 [1] CRAN (R 4.1.1) ## pillar 1.6.2 2021-07-29 [1] CRAN (R 4.1.1) ## pkgconfig 2.0.3 2019-09-22 [1] CRAN (R 4.1.1) ## purrr * 0.3.4 2020-04-17 [1] CRAN (R 4.1.1) ## quanteda * 3.1.0 2021-08-17 [1] CRAN (R 4.1.1) ## R6 2.5.1 2021-08-19 [1] CRAN (R 4.1.1) ## Rcpp 1.0.7 2021-07-07 [1] CRAN (R 4.1.1) ## RcppParallel 5.1.4 2021-05-04 [1] CRAN (R 4.1.1) ## readr * 2.0.1 2021-08-10 [1] CRAN (R 4.1.1) ## readxl 1.3.1 2019-03-13 [1] CRAN (R 4.1.1) ## reprex 2.0.1 2021-08-05 [1] CRAN (R 4.1.1) ## rlang 0.4.11 2021-04-30 [1] CRAN (R 4.1.1) ## rmarkdown 2.10 2021-08-06 [1] CRAN (R 4.1.1) ## rstudioapi 0.13 2020-11-12 [1] CRAN (R 4.1.1) ## rvest 1.0.1 2021-07-26 [1] CRAN (R 4.1.1) ## sass 0.4.0 2021-05-12 [1] CRAN (R 4.1.1) ## scales 1.1.1 2020-05-11 [1] CRAN (R 4.1.1) ## sessioninfo 1.1.1 2018-11-05 [1] CRAN (R 4.1.1) ## SnowballC 0.7.0 2020-04-01 [1] CRAN (R 4.1.1) ## stopwords 2.2 2021-02-10 [1] CRAN (R 4.1.1) ## stringi 1.7.4 2021-08-25 [1] CRAN (R 4.1.1) ## stringr * 1.4.0 2019-02-10 [1] CRAN (R 4.1.1) ## tibble * 3.1.4 2021-08-25 [1] CRAN (R 4.1.1) ## tidyr * 1.1.3 2021-03-03 [1] CRAN (R 4.1.1) ## tidyselect 1.1.1 2021-04-30 [1] CRAN (R 4.1.1) ## tidytext * 0.3.1 2021-04-10 [1] CRAN (R 4.1.1) ## tidyverse * 1.3.1 2021-04-15 [1] CRAN (R 4.1.1) ## tokenizers 0.2.1 2018-03-29 [1] CRAN (R 4.1.1) ## tzdb 0.1.2 2021-07-20 [1] CRAN (R 4.1.1) ## utf8 1.2.2 2021-07-24 [1] CRAN (R 4.1.1) ## vctrs 0.3.8 2021-04-29 [1] CRAN (R 4.1.1) ## withr 2.4.2 2021-04-18 [1] CRAN (R 4.1.1) ## xfun 0.25 2021-08-06 [1] CRAN (R 4.1.1) ## xml2 1.3.2 2020-04-23 [1] CRAN (R 4.1.1) ## yaml 2.2.1 2020-02-01 [1] CRAN (R 4.1.1) ## ## [1] /home/jakobtures/R/x86_64-pc-linux-gnu-library/4.1 ## [2] /usr/local/lib/R/site-library ## [3] /usr/lib/R/site-library ## [4] /usr/lib/R/library "],["R1.html", "1 R Basics 1.1 Installation 1.2 Erste Schritte 1.3 Objekte 1.4 Vektoren 1.5 Weitere Datentypen 1.6 If/Else statements 1.7 For-loops", " 1 R Basics 1.1 Installation 1.1.1 R 1.1.2 RStudio 1.2 Erste Schritte 1.2.1 Hello World! 1.2.2 Rechnen mit R 1.2.3 Logische Vergleiche 1.3 Objekte 1.4 Vektoren 1.4.1 Subsetting 1.4.2 Typen von Vektoren 1.5 Weitere Datentypen 1.5.1 Dataframes 1.5.2 Listen 1.5.3 Matrizen 1.6 If/Else statements 1.7 For-loops "],["R2.html", "2 RStudio &amp; das tidyverse 2.1 RStudio workflow 2.2 R packages 2.3 Funktionen 2.4 tidyverse 2.5 Hilfe?", " 2 RStudio &amp; das tidyverse 2.1 RStudio workflow 2.1.1 R scripts 2.1.2 Projekte 2.1.3 Kommentare 2.1.4 Speichern 2.2 R packages 2.2.1 Installieren und Laden 2.3 Funktionen 2.3.1 namesspaces 2.4 tidyverse 2.4.1 tibbles 2.4.2 tidydata 2.5 Hilfe? 2.5.1 Hilfe! 2.5.2 Empfohlene externe Resourcen "],["R3.html", "3 dplyr &amp; ggplot2 3.1 Transformation mit dplyr 3.2 Graphische Analyse mit ggplot2", " 3 dplyr &amp; ggplot2 3.1 Transformation mit dplyr 3.1.1 mutate() 3.1.2 select() 3.1.3 rename() 3.1.4 filter() 3.1.5 summarise() &amp; group_by() 3.1.6 Export von Tabellen 3.2 Graphische Analyse mit ggplot2 3.2.1 ggplot2 syntax 3.2.2 aesthetics &amp; geoms 3.2.3 Beispiele 3.2.3.1 kontinuierliches x &amp; y 3.2.3.2 kategoriales x 3.2.3.3 kontinuierliches x 3.2.4 Graphiken exportieren "],["BT19.html", "4 Plenarprotokolle des 19. Bundestags", " 4 Plenarprotokolle des 19. Bundestags "],["tidytext1.html", "5 tidytext format &amp; tokenisation", " 5 tidytext format &amp; tokenisation "],["tidytext2.html", "6 tf &amp; tf-idf", " 6 tf &amp; tf-idf "],["tidytext3.html", "7 n-grams &amp; correlations", " 7 n-grams &amp; correlations "],["tidytext4.html", "8 Sentiment Analyse", " 8 Sentiment Analyse "],["quanteda1.html", "9 corpus, tokenisation &amp; DTM", " 9 corpus, tokenisation &amp; DTM "],["quanteda2.html", "10 Anwendungsbeispiele 1", " 10 Anwendungsbeispiele 1 "],["quanteda3.html", "11 Anwendungsbeispiele 2", " 11 Anwendungsbeispiele 2 "],["ML1.html", "12 Unsupervised", " 12 Unsupervised "],["ML2.html", "13 Supervised", " 13 Supervised "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
